{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code for Comparing NILM algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guptasoumya/anaconda3/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/guptasoumya/anaconda3/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/guptasoumya/anaconda3/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/guptasoumya/anaconda3/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import time\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from six import iteritems\n",
    "from nilmtk import DataSet\n",
    "from nilmtk.utils import print_dict\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (13, 6)\n",
    "#plt.style.use('ggplot')\n",
    "from datetime import datetime as datetime2\n",
    "from datetime import timedelta\n",
    "\n",
    "import nilmtk\n",
    "from nilmtk.disaggregate.maximum_likelihood_estimation import MLE\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from scipy.stats import poisson, norm\n",
    "from sklearn import mixture\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "rcParams['figure.figsize'] = (13, 6)\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.disaggregate import CombinatorialOptimisation, FHMM\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/guptasoumya/Desktop/capstone_nilmtk/nilmtk/docs/manual/user_guide'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataSet('/Users/guptasoumya/Desktop/capstone_nilmtk/nilmtk/data/REDD/redd.h5')\n",
    "test = DataSet('/Users/guptasoumya/Desktop/capstone_nilmtk/nilmtk/data/REDD/redd.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use building 1 for demo purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "building = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split data at April 30th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_window(end=\"30-4-2011\")\n",
    "test.set_window(start=\"30-4-2011\")\n",
    "\n",
    "\n",
    "train_elec = train.buildings[building].elec\n",
    "test_elec = test.buildings[building].elec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting top-5 appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_train_elec = train_elec.submeters().select_using_appliances(type=['fridge', 'washer dryer', 'microwave', 'light', 'dish washer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and disaggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf, test_elec, sample_period, timezone):\n",
    "    pred = {}\n",
    "    gt= {}\n",
    "\n",
    "    for i, chunk in enumerate(test_elec.mains().load(sample_period=sample_period)):\n",
    "        chunk_drop_na = chunk.dropna()\n",
    "        pred[i] = clf.disaggregate_chunk(chunk_drop_na)\n",
    "        gt[i]={}\n",
    "\n",
    "        for meter in test_elec.submeters().meters:\n",
    "            # Only use the meters that we trained on (this saves time!)    \n",
    "            gt[i][meter] = next(meter.load(sample_period=sample_period))\n",
    "        gt[i] = pd.DataFrame({k:v.squeeze() for k,v in iteritems(gt[i])}, index=next(iter(gt[i].values())).index).dropna()\n",
    "        \n",
    "    # If everything can fit in memory\n",
    "    gt_overall = pd.concat(gt)\n",
    "    gt_overall.index = gt_overall.index.droplevel()\n",
    "    pred_overall = pd.concat(pred)\n",
    "    pred_overall.index = pred_overall.index.droplevel()\n",
    "\n",
    "    # Having the same order of columns\n",
    "    gt_overall = gt_overall[pred_overall.columns]\n",
    "    \n",
    "    #Intersection of index\n",
    "    gt_index_utc = gt_overall.index.tz_convert(\"UTC\")\n",
    "    pred_index_utc = pred_overall.index.tz_convert(\"UTC\")\n",
    "    common_index_utc = gt_index_utc.intersection(pred_index_utc)\n",
    "    \n",
    "    \n",
    "    common_index_local = common_index_utc.tz_convert(timezone)\n",
    "    gt_overall = gt_overall.ix[common_index_local]\n",
    "    pred_overall = pred_overall.ix[common_index_local]\n",
    "    appliance_labels = [m.label() for m in gt_overall.columns.values]\n",
    "    gt_overall.columns = appliance_labels\n",
    "    pred_overall.columns = appliance_labels\n",
    "    return gt_overall, pred_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "CO\n",
      "********************\n",
      "Training model for submeter 'ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])'\n",
      "Training model for submeter 'MeterGroup(meters=\n",
      "  ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")'\n",
      "Loading data for meter ElecMeterID(instance=20, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Training model for submeter 'ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=17, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=2)])'\n",
      "Training model for submeter 'ElecMeter(instance=18, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=3)])'\n",
      "Training model for submeter 'ElecMeter(instance=6, building=1, dataset='REDD', appliances=[Appliance(type='dish washer', instance=1)])'\n",
      "Done training!\n",
      "Loading data for meter ElecMeterID(instance=2, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Estimating power demand for 'ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])'\n",
      "Estimating power demand for 'MeterGroup(meters=\n",
      "  ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")'\n",
      "Estimating power demand for 'ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=17, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=2)])'\n",
      "Estimating power demand for 'ElecMeter(instance=18, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=3)])'\n",
      "Estimating power demand for 'ElecMeter(instance=6, building=1, dataset='REDD', appliances=[Appliance(type='dish washer', instance=1)])'\n",
      "Loading data for meter ElecMeterID(instance=4, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Loading data for meter ElecMeterID(instance=20, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "********************\n",
      "FHMM\n",
      "********************\n",
      "Training model for submeter 'ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])'\n",
      "Loading data for meter ElecMeterID(instance=20, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Training model for submeter 'MeterGroup(meters=\n",
      "  ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")'\n",
      "Training model for submeter 'ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=17, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=2)])'\n",
      "Training model for submeter 'ElecMeter(instance=18, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=3)])'\n",
      "Training model for submeter 'ElecMeter(instance=6, building=1, dataset='REDD', appliances=[Appliance(type='dish washer', instance=1)])'\n",
      "Loading data for meter ElecMeterID(instance=2, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n"
     ]
    }
   ],
   "source": [
    "classifiers = {'CO':CombinatorialOptimisation(), 'FHMM':FHMM()}\n",
    "predictions = {}\n",
    "sample_period = 120\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(\"*\"*20)\n",
    "    print(clf_name)\n",
    "    print(\"*\" *20)\n",
    "    clf.train(top_5_train_elec, sample_period=sample_period)\n",
    "    gt, predictions[clf_name] = predict(clf, test_elec, 120, train.metadata['timezone'])\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(gt, pred):\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    mae_error = {}\n",
    "    for appliance in gt.columns:\n",
    "        mae_error[appliance] = mean_absolute_error(gt[appliance], pred[appliance])\n",
    "    return pd.Series(mae_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = {}\n",
    "for clf_name in classifiers.keys():\n",
    "    mae[clf_name] = compute_mae(gt, predictions[clf_name])\n",
    "mae = pd.DataFrame(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(gt, pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    rms_error = {}\n",
    "    for appliance in gt.columns:\n",
    "        rms_error[appliance] = np.sqrt(mean_squared_error(gt[appliance], pred[appliance]))\n",
    "    return pd.Series(rms_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = {}\n",
    "for clf_name in classifiers.keys():\n",
    "    rmse[clf_name] = compute_rmse(gt, predictions[clf_name])\n",
    "rmse = pd.DataFrame(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing MAE for MLE of different appliances\n",
    "mae['MLE'] = pd.Series(4.941888,170.84703,28.329752,9.264734,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
